{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emukit and Experimental Design\n",
    "==============================\n",
    "\n",
    "### [Neil D. Lawrence](http://inverseprobability.com)\n",
    "\n",
    "### 2020-10-30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abstract**: In this lecture we introduce Emukit, a software framework\n",
    "for decision programming via surrogage modelling and emulation. We’ll\n",
    "then show an example of the use of the framework with experimental\n",
    "design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\tk}[1]{}\n",
    "\\newcommand{\\Amatrix}{\\mathbf{A}}\n",
    "\\newcommand{\\KL}[2]{\\text{KL}\\left( #1\\,\\|\\,#2 \\right)}\n",
    "\\newcommand{\\Kaast}{\\kernelMatrix_{\\mathbf{ \\ast}\\mathbf{ \\ast}}}\n",
    "\\newcommand{\\Kastu}{\\kernelMatrix_{\\mathbf{ \\ast} \\inducingVector}}\n",
    "\\newcommand{\\Kff}{\\kernelMatrix_{\\mappingFunctionVector \\mappingFunctionVector}}\n",
    "\\newcommand{\\Kfu}{\\kernelMatrix_{\\mappingFunctionVector \\inducingVector}}\n",
    "\\newcommand{\\Kuast}{\\kernelMatrix_{\\inducingVector \\bf\\ast}}\n",
    "\\newcommand{\\Kuf}{\\kernelMatrix_{\\inducingVector \\mappingFunctionVector}}\n",
    "\\newcommand{\\Kuu}{\\kernelMatrix_{\\inducingVector \\inducingVector}}\n",
    "\\newcommand{\\Kuui}{\\Kuu^{-1}}\n",
    "\\newcommand{\\Qaast}{\\mathbf{Q}_{\\bf \\ast \\ast}}\n",
    "\\newcommand{\\Qastf}{\\mathbf{Q}_{\\ast \\mappingFunction}}\n",
    "\\newcommand{\\Qfast}{\\mathbf{Q}_{\\mappingFunctionVector \\bf \\ast}}\n",
    "\\newcommand{\\Qff}{\\mathbf{Q}_{\\mappingFunctionVector \\mappingFunctionVector}}\n",
    "\\newcommand{\\aMatrix}{\\mathbf{A}}\n",
    "\\newcommand{\\aScalar}{a}\n",
    "\\newcommand{\\aVector}{\\mathbf{a}}\n",
    "\\newcommand{\\acceleration}{a}\n",
    "\\newcommand{\\bMatrix}{\\mathbf{B}}\n",
    "\\newcommand{\\bScalar}{b}\n",
    "\\newcommand{\\bVector}{\\mathbf{b}}\n",
    "\\newcommand{\\basisFunc}{\\phi}\n",
    "\\newcommand{\\basisFuncVector}{\\boldsymbol{ \\basisFunc}}\n",
    "\\newcommand{\\basisFunction}{\\phi}\n",
    "\\newcommand{\\basisLocation}{\\mu}\n",
    "\\newcommand{\\basisMatrix}{\\boldsymbol{ \\Phi}}\n",
    "\\newcommand{\\basisScalar}{\\basisFunction}\n",
    "\\newcommand{\\basisVector}{\\boldsymbol{ \\basisFunction}}\n",
    "\\newcommand{\\activationFunction}{\\phi}\n",
    "\\newcommand{\\activationMatrix}{\\boldsymbol{ \\Phi}}\n",
    "\\newcommand{\\activationScalar}{\\basisFunction}\n",
    "\\newcommand{\\activationVector}{\\boldsymbol{ \\basisFunction}}\n",
    "\\newcommand{\\bigO}{\\mathcal{O}}\n",
    "\\newcommand{\\binomProb}{\\pi}\n",
    "\\newcommand{\\cMatrix}{\\mathbf{C}}\n",
    "\\newcommand{\\cbasisMatrix}{\\hat{\\boldsymbol{ \\Phi}}}\n",
    "\\newcommand{\\cdataMatrix}{\\hat{\\dataMatrix}}\n",
    "\\newcommand{\\cdataScalar}{\\hat{\\dataScalar}}\n",
    "\\newcommand{\\cdataVector}{\\hat{\\dataVector}}\n",
    "\\newcommand{\\centeredKernelMatrix}{\\mathbf{ \\MakeUppercase{\\centeredKernelScalar}}}\n",
    "\\newcommand{\\centeredKernelScalar}{b}\n",
    "\\newcommand{\\centeredKernelVector}{\\centeredKernelScalar}\n",
    "\\newcommand{\\centeringMatrix}{\\mathbf{H}}\n",
    "\\newcommand{\\chiSquaredDist}[2]{\\chi_{#1}^{2}\\left(#2\\right)}\n",
    "\\newcommand{\\chiSquaredSamp}[1]{\\chi_{#1}^{2}}\n",
    "\\newcommand{\\conditionalCovariance}{\\boldsymbol{ \\Sigma}}\n",
    "\\newcommand{\\coregionalizationMatrix}{\\mathbf{B}}\n",
    "\\newcommand{\\coregionalizationScalar}{b}\n",
    "\\newcommand{\\coregionalizationVector}{\\mathbf{ \\coregionalizationScalar}}\n",
    "\\newcommand{\\covDist}[2]{\\text{cov}_{#2}\\left(#1\\right)}\n",
    "\\newcommand{\\covSamp}[1]{\\text{cov}\\left(#1\\right)}\n",
    "\\newcommand{\\covarianceScalar}{c}\n",
    "\\newcommand{\\covarianceVector}{\\mathbf{ \\covarianceScalar}}\n",
    "\\newcommand{\\covarianceMatrix}{\\mathbf{C}}\n",
    "\\newcommand{\\covarianceMatrixTwo}{\\boldsymbol{ \\Sigma}}\n",
    "\\newcommand{\\croupierScalar}{s}\n",
    "\\newcommand{\\croupierVector}{\\mathbf{ \\croupierScalar}}\n",
    "\\newcommand{\\croupierMatrix}{\\mathbf{ \\MakeUppercase{\\croupierScalar}}}\n",
    "\\newcommand{\\dataDim}{p}\n",
    "\\newcommand{\\dataIndex}{i}\n",
    "\\newcommand{\\dataIndexTwo}{j}\n",
    "\\newcommand{\\dataMatrix}{\\mathbf{Y}}\n",
    "\\newcommand{\\dataScalar}{y}\n",
    "\\newcommand{\\dataSet}{\\mathcal{D}}\n",
    "\\newcommand{\\dataStd}{\\sigma}\n",
    "\\newcommand{\\dataVector}{\\mathbf{ \\dataScalar}}\n",
    "\\newcommand{\\decayRate}{d}\n",
    "\\newcommand{\\degreeMatrix}{\\mathbf{ \\MakeUppercase{\\degreeScalar}}}\n",
    "\\newcommand{\\degreeScalar}{d}\n",
    "\\newcommand{\\degreeVector}{\\mathbf{ \\degreeScalar}}\n",
    "\\newcommand{\\diag}[1]{\\text{diag}\\left(#1\\right)}\n",
    "\\newcommand{\\diagonalMatrix}{\\mathbf{D}}\n",
    "\\newcommand{\\diff}[2]{\\frac{\\text{d}#1}{\\text{d}#2}}\n",
    "\\newcommand{\\diffTwo}[2]{\\frac{\\text{d}^2#1}{\\text{d}#2^2}}\n",
    "\\newcommand{\\displacement}{x}\n",
    "\\newcommand{\\displacementVector}{\\textbf{\\displacement}}\n",
    "\\newcommand{\\distanceMatrix}{\\mathbf{ \\MakeUppercase{\\distanceScalar}}}\n",
    "\\newcommand{\\distanceScalar}{d}\n",
    "\\newcommand{\\distanceVector}{\\mathbf{ \\distanceScalar}}\n",
    "\\newcommand{\\eigenvaltwo}{\\ell}\n",
    "\\newcommand{\\eigenvaltwoMatrix}{\\mathbf{L}}\n",
    "\\newcommand{\\eigenvaltwoVector}{\\mathbf{l}}\n",
    "\\newcommand{\\eigenvalue}{\\lambda}\n",
    "\\newcommand{\\eigenvalueMatrix}{\\boldsymbol{ \\Lambda}}\n",
    "\\newcommand{\\eigenvalueVector}{\\boldsymbol{ \\lambda}}\n",
    "\\newcommand{\\eigenvector}{\\mathbf{ \\eigenvectorScalar}}\n",
    "\\newcommand{\\eigenvectorMatrix}{\\mathbf{U}}\n",
    "\\newcommand{\\eigenvectorScalar}{u}\n",
    "\\newcommand{\\eigenvectwo}{\\mathbf{v}}\n",
    "\\newcommand{\\eigenvectwoMatrix}{\\mathbf{V}}\n",
    "\\newcommand{\\eigenvectwoScalar}{v}\n",
    "\\newcommand{\\entropy}[1]{\\mathcal{H}\\left(#1\\right)}\n",
    "\\newcommand{\\errorFunction}{E}\n",
    "\\newcommand{\\expDist}[2]{\\left<#1\\right>_{#2}}\n",
    "\\newcommand{\\expSamp}[1]{\\left<#1\\right>}\n",
    "\\newcommand{\\expectation}[1]{\\left\\langle #1 \\right\\rangle }\n",
    "\\newcommand{\\expectationDist}[2]{\\left\\langle #1 \\right\\rangle _{#2}}\n",
    "\\newcommand{\\expectedDistanceMatrix}{\\mathcal{D}}\n",
    "\\newcommand{\\eye}{\\mathbf{I}}\n",
    "\\newcommand{\\fantasyDim}{r}\n",
    "\\newcommand{\\fantasyMatrix}{\\mathbf{ \\MakeUppercase{\\fantasyScalar}}}\n",
    "\\newcommand{\\fantasyScalar}{z}\n",
    "\\newcommand{\\fantasyVector}{\\mathbf{ \\fantasyScalar}}\n",
    "\\newcommand{\\featureStd}{\\varsigma}\n",
    "\\newcommand{\\gammaCdf}[3]{\\mathcal{GAMMA CDF}\\left(#1|#2,#3\\right)}\n",
    "\\newcommand{\\gammaDist}[3]{\\mathcal{G}\\left(#1|#2,#3\\right)}\n",
    "\\newcommand{\\gammaSamp}[2]{\\mathcal{G}\\left(#1,#2\\right)}\n",
    "\\newcommand{\\gaussianDist}[3]{\\mathcal{N}\\left(#1|#2,#3\\right)}\n",
    "\\newcommand{\\gaussianSamp}[2]{\\mathcal{N}\\left(#1,#2\\right)}\n",
    "\\newcommand{\\given}{|}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\heaviside}{H}\n",
    "\\newcommand{\\hiddenMatrix}{\\mathbf{ \\MakeUppercase{\\hiddenScalar}}}\n",
    "\\newcommand{\\hiddenScalar}{h}\n",
    "\\newcommand{\\hiddenVector}{\\mathbf{ \\hiddenScalar}}\n",
    "\\newcommand{\\identityMatrix}{\\eye}\n",
    "\\newcommand{\\inducingInputScalar}{z}\n",
    "\\newcommand{\\inducingInputVector}{\\mathbf{ \\inducingInputScalar}}\n",
    "\\newcommand{\\inducingInputMatrix}{\\mathbf{Z}}\n",
    "\\newcommand{\\inducingScalar}{u}\n",
    "\\newcommand{\\inducingVector}{\\mathbf{ \\inducingScalar}}\n",
    "\\newcommand{\\inducingMatrix}{\\mathbf{U}}\n",
    "\\newcommand{\\inlineDiff}[2]{\\text{d}#1/\\text{d}#2}\n",
    "\\newcommand{\\inputDim}{q}\n",
    "\\newcommand{\\inputMatrix}{\\mathbf{X}}\n",
    "\\newcommand{\\inputScalar}{x}\n",
    "\\newcommand{\\inputSpace}{\\mathcal{X}}\n",
    "\\newcommand{\\inputVals}{\\inputVector}\n",
    "\\newcommand{\\inputVector}{\\mathbf{ \\inputScalar}}\n",
    "\\newcommand{\\iterNum}{k}\n",
    "\\newcommand{\\kernel}{\\kernelScalar}\n",
    "\\newcommand{\\kernelMatrix}{\\mathbf{K}}\n",
    "\\newcommand{\\kernelScalar}{k}\n",
    "\\newcommand{\\kernelVector}{\\mathbf{ \\kernelScalar}}\n",
    "\\newcommand{\\kff}{\\kernelScalar_{\\mappingFunction \\mappingFunction}}\n",
    "\\newcommand{\\kfu}{\\kernelVector_{\\mappingFunction \\inducingScalar}}\n",
    "\\newcommand{\\kuf}{\\kernelVector_{\\inducingScalar \\mappingFunction}}\n",
    "\\newcommand{\\kuu}{\\kernelVector_{\\inducingScalar \\inducingScalar}}\n",
    "\\newcommand{\\lagrangeMultiplier}{\\lambda}\n",
    "\\newcommand{\\lagrangeMultiplierMatrix}{\\boldsymbol{ \\Lambda}}\n",
    "\\newcommand{\\lagrangian}{L}\n",
    "\\newcommand{\\laplacianFactor}{\\mathbf{ \\MakeUppercase{\\laplacianFactorScalar}}}\n",
    "\\newcommand{\\laplacianFactorScalar}{m}\n",
    "\\newcommand{\\laplacianFactorVector}{\\mathbf{ \\laplacianFactorScalar}}\n",
    "\\newcommand{\\laplacianMatrix}{\\mathbf{L}}\n",
    "\\newcommand{\\laplacianScalar}{\\ell}\n",
    "\\newcommand{\\laplacianVector}{\\mathbf{ \\ell}}\n",
    "\\newcommand{\\latentDim}{q}\n",
    "\\newcommand{\\latentDistanceMatrix}{\\boldsymbol{ \\Delta}}\n",
    "\\newcommand{\\latentDistanceScalar}{\\delta}\n",
    "\\newcommand{\\latentDistanceVector}{\\boldsymbol{ \\delta}}\n",
    "\\newcommand{\\latentForce}{f}\n",
    "\\newcommand{\\latentFunction}{u}\n",
    "\\newcommand{\\latentFunctionVector}{\\mathbf{ \\latentFunction}}\n",
    "\\newcommand{\\latentFunctionMatrix}{\\mathbf{ \\MakeUppercase{\\latentFunction}}}\n",
    "\\newcommand{\\latentIndex}{j}\n",
    "\\newcommand{\\latentScalar}{z}\n",
    "\\newcommand{\\latentVector}{\\mathbf{ \\latentScalar}}\n",
    "\\newcommand{\\latentMatrix}{\\mathbf{Z}}\n",
    "\\newcommand{\\learnRate}{\\eta}\n",
    "\\newcommand{\\lengthScale}{\\ell}\n",
    "\\newcommand{\\rbfWidth}{\\ell}\n",
    "\\newcommand{\\likelihoodBound}{\\mathcal{L}}\n",
    "\\newcommand{\\likelihoodFunction}{L}\n",
    "\\newcommand{\\locationScalar}{\\mu}\n",
    "\\newcommand{\\locationVector}{\\boldsymbol{ \\locationScalar}}\n",
    "\\newcommand{\\locationMatrix}{\\mathbf{M}}\n",
    "\\newcommand{\\variance}[1]{\\text{var}\\left( #1 \\right)}\n",
    "\\newcommand{\\mappingFunction}{f}\n",
    "\\newcommand{\\mappingFunctionMatrix}{\\mathbf{F}}\n",
    "\\newcommand{\\mappingFunctionTwo}{g}\n",
    "\\newcommand{\\mappingFunctionTwoMatrix}{\\mathbf{G}}\n",
    "\\newcommand{\\mappingFunctionTwoVector}{\\mathbf{ \\mappingFunctionTwo}}\n",
    "\\newcommand{\\mappingFunctionVector}{\\mathbf{ \\mappingFunction}}\n",
    "\\newcommand{\\scaleScalar}{s}\n",
    "\\newcommand{\\mappingScalar}{w}\n",
    "\\newcommand{\\mappingVector}{\\mathbf{ \\mappingScalar}}\n",
    "\\newcommand{\\mappingMatrix}{\\mathbf{W}}\n",
    "\\newcommand{\\mappingScalarTwo}{v}\n",
    "\\newcommand{\\mappingVectorTwo}{\\mathbf{ \\mappingScalarTwo}}\n",
    "\\newcommand{\\mappingMatrixTwo}{\\mathbf{V}}\n",
    "\\newcommand{\\maxIters}{K}\n",
    "\\newcommand{\\meanMatrix}{\\mathbf{M}}\n",
    "\\newcommand{\\meanScalar}{\\mu}\n",
    "\\newcommand{\\meanTwoMatrix}{\\mathbf{M}}\n",
    "\\newcommand{\\meanTwoScalar}{m}\n",
    "\\newcommand{\\meanTwoVector}{\\mathbf{ \\meanTwoScalar}}\n",
    "\\newcommand{\\meanVector}{\\boldsymbol{ \\meanScalar}}\n",
    "\\newcommand{\\mrnaConcentration}{m}\n",
    "\\newcommand{\\naturalFrequency}{\\omega}\n",
    "\\newcommand{\\neighborhood}[1]{\\mathcal{N}\\left( #1 \\right)}\n",
    "\\newcommand{\\neilurl}{http://inverseprobability.com/}\n",
    "\\newcommand{\\noiseMatrix}{\\boldsymbol{ E}}\n",
    "\\newcommand{\\noiseScalar}{\\epsilon}\n",
    "\\newcommand{\\noiseVector}{\\boldsymbol{ \\epsilon}}\n",
    "\\newcommand{\\norm}[1]{\\left\\Vert #1 \\right\\Vert}\n",
    "\\newcommand{\\normalizedLaplacianMatrix}{\\hat{\\mathbf{L}}}\n",
    "\\newcommand{\\normalizedLaplacianScalar}{\\hat{\\ell}}\n",
    "\\newcommand{\\normalizedLaplacianVector}{\\hat{\\mathbf{ \\ell}}}\n",
    "\\newcommand{\\numActive}{m}\n",
    "\\newcommand{\\numBasisFunc}{m}\n",
    "\\newcommand{\\numComponents}{m}\n",
    "\\newcommand{\\numComps}{K}\n",
    "\\newcommand{\\numData}{n}\n",
    "\\newcommand{\\numFeatures}{K}\n",
    "\\newcommand{\\numHidden}{h}\n",
    "\\newcommand{\\numInducing}{m}\n",
    "\\newcommand{\\numLayers}{\\ell}\n",
    "\\newcommand{\\numNeighbors}{K}\n",
    "\\newcommand{\\numSequences}{s}\n",
    "\\newcommand{\\numSuccess}{s}\n",
    "\\newcommand{\\numTasks}{m}\n",
    "\\newcommand{\\numTime}{T}\n",
    "\\newcommand{\\numTrials}{S}\n",
    "\\newcommand{\\outputIndex}{j}\n",
    "\\newcommand{\\paramVector}{\\boldsymbol{ \\theta}}\n",
    "\\newcommand{\\parameterMatrix}{\\boldsymbol{ \\Theta}}\n",
    "\\newcommand{\\parameterScalar}{\\theta}\n",
    "\\newcommand{\\parameterVector}{\\boldsymbol{ \\parameterScalar}}\n",
    "\\newcommand{\\partDiff}[2]{\\frac{\\partial#1}{\\partial#2}}\n",
    "\\newcommand{\\precisionScalar}{j}\n",
    "\\newcommand{\\precisionVector}{\\mathbf{ \\precisionScalar}}\n",
    "\\newcommand{\\precisionMatrix}{\\mathbf{J}}\n",
    "\\newcommand{\\pseudotargetScalar}{\\widetilde{y}}\n",
    "\\newcommand{\\pseudotargetVector}{\\mathbf{ \\pseudotargetScalar}}\n",
    "\\newcommand{\\pseudotargetMatrix}{\\mathbf{ \\widetilde{Y}}}\n",
    "\\newcommand{\\rank}[1]{\\text{rank}\\left(#1\\right)}\n",
    "\\newcommand{\\rayleighDist}[2]{\\mathcal{R}\\left(#1|#2\\right)}\n",
    "\\newcommand{\\rayleighSamp}[1]{\\mathcal{R}\\left(#1\\right)}\n",
    "\\newcommand{\\responsibility}{r}\n",
    "\\newcommand{\\rotationScalar}{r}\n",
    "\\newcommand{\\rotationVector}{\\mathbf{ \\rotationScalar}}\n",
    "\\newcommand{\\rotationMatrix}{\\mathbf{R}}\n",
    "\\newcommand{\\sampleCovScalar}{s}\n",
    "\\newcommand{\\sampleCovVector}{\\mathbf{ \\sampleCovScalar}}\n",
    "\\newcommand{\\sampleCovMatrix}{\\mathbf{s}}\n",
    "\\newcommand{\\scalarProduct}[2]{\\left\\langle{#1},{#2}\\right\\rangle}\n",
    "\\newcommand{\\sign}[1]{\\text{sign}\\left(#1\\right)}\n",
    "\\newcommand{\\sigmoid}[1]{\\sigma\\left(#1\\right)}\n",
    "\\newcommand{\\singularvalue}{\\ell}\n",
    "\\newcommand{\\singularvalueMatrix}{\\mathbf{L}}\n",
    "\\newcommand{\\singularvalueVector}{\\mathbf{l}}\n",
    "\\newcommand{\\sorth}{\\mathbf{u}}\n",
    "\\newcommand{\\spar}{\\lambda}\n",
    "\\newcommand{\\trace}[1]{\\text{tr}\\left(#1\\right)}\n",
    "\\newcommand{\\BasalRate}{B}\n",
    "\\newcommand{\\DampingCoefficient}{C}\n",
    "\\newcommand{\\DecayRate}{D}\n",
    "\\newcommand{\\Displacement}{X}\n",
    "\\newcommand{\\LatentForce}{F}\n",
    "\\newcommand{\\Mass}{M}\n",
    "\\newcommand{\\Sensitivity}{S}\n",
    "\\newcommand{\\basalRate}{b}\n",
    "\\newcommand{\\dampingCoefficient}{c}\n",
    "\\newcommand{\\mass}{m}\n",
    "\\newcommand{\\sensitivity}{s}\n",
    "\\newcommand{\\springScalar}{\\kappa}\n",
    "\\newcommand{\\springVector}{\\boldsymbol{ \\kappa}}\n",
    "\\newcommand{\\springMatrix}{\\boldsymbol{ \\mathcal{K}}}\n",
    "\\newcommand{\\tfConcentration}{p}\n",
    "\\newcommand{\\tfDecayRate}{\\delta}\n",
    "\\newcommand{\\tfMrnaConcentration}{f}\n",
    "\\newcommand{\\tfVector}{\\mathbf{ \\tfConcentration}}\n",
    "\\newcommand{\\velocity}{v}\n",
    "\\newcommand{\\sufficientStatsScalar}{g}\n",
    "\\newcommand{\\sufficientStatsVector}{\\mathbf{ \\sufficientStatsScalar}}\n",
    "\\newcommand{\\sufficientStatsMatrix}{\\mathbf{G}}\n",
    "\\newcommand{\\switchScalar}{s}\n",
    "\\newcommand{\\switchVector}{\\mathbf{ \\switchScalar}}\n",
    "\\newcommand{\\switchMatrix}{\\mathbf{S}}\n",
    "\\newcommand{\\tr}[1]{\\text{tr}\\left(#1\\right)}\n",
    "\\newcommand{\\loneNorm}[1]{\\left\\Vert #1 \\right\\Vert_1}\n",
    "\\newcommand{\\ltwoNorm}[1]{\\left\\Vert #1 \\right\\Vert_2}\n",
    "\\newcommand{\\onenorm}[1]{\\left\\vert#1\\right\\vert_1}\n",
    "\\newcommand{\\twonorm}[1]{\\left\\Vert #1 \\right\\Vert}\n",
    "\\newcommand{\\vScalar}{v}\n",
    "\\newcommand{\\vVector}{\\mathbf{v}}\n",
    "\\newcommand{\\vMatrix}{\\mathbf{V}}\n",
    "\\newcommand{\\varianceDist}[2]{\\text{var}_{#2}\\left( #1 \\right)}\n",
    "\\newcommand{\\vecb}[1]{\\left(#1\\right):}\n",
    "\\newcommand{\\weightScalar}{w}\n",
    "\\newcommand{\\weightVector}{\\mathbf{ \\weightScalar}}\n",
    "\\newcommand{\\weightMatrix}{\\mathbf{W}}\n",
    "\\newcommand{\\weightedAdjacencyMatrix}{\\mathbf{A}}\n",
    "\\newcommand{\\weightedAdjacencyScalar}{a}\n",
    "\\newcommand{\\weightedAdjacencyVector}{\\mathbf{ \\weightedAdjacencyScalar}}\n",
    "\\newcommand{\\onesVector}{\\mathbf{1}}\n",
    "\\newcommand{\\zerosVector}{\\mathbf{0}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!---->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
    "<!--\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emukit\n",
    "======\n",
    "\n",
    "<svg viewBox=\"0 0 200 200\" style=\"width:15%\">\n",
    "\n",
    "<defs> <clipPath id=\"clip0\">\n",
    "\n",
    "<style>\n",
    "circle {\n",
    "  fill: black;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\"/> </clipPath> </defs>\n",
    "\n",
    "<title>\n",
    "\n",
    "Javier Gonzalez\n",
    "\n",
    "</title>\n",
    "\n",
    "<image preserveAspectRatio=\"xMinYMin slice\" width=\"100%\" xlink:href=\"../slides/diagrams/people/javier-gonzalez.png\" clip-path=\"url(#clip0)\"/>\n",
    "\n",
    "</svg>\n",
    "\n",
    "The Emukit software we will be using across the next part of this module\n",
    "is a python software library that facilitates emulation of systems. The\n",
    "software’s origins go back to work done by [Javier\n",
    "Gonzalez](https://javiergonzalezh.github.io/) as part of his\n",
    "post-doctoral project at the University of Sheffield. Javier led the\n",
    "design and build of a Bayesian optimization software. The package\n",
    "`GPyOpt` worked with the SheffieldML software GPy for performing\n",
    "Bayesian optimization.\n",
    "\n",
    "`GPyOpt` has a modular design that allows the user to provide their own\n",
    "surrogate models, the package is build with `GPy` as a surrogate model\n",
    "in mind, but other surrogate models can also be wrapped and integrated.\n",
    "\n",
    "However, `GPyOpt` doesn’t allow the full flexibility of surrogate\n",
    "modelling for domains like experimental design, sensitivity analysis\n",
    "etc.\n",
    "\n",
    "Emukit was designed and built for a more general approach. The software\n",
    "is MIT licensed and its design and implementation was led by Javier\n",
    "Gonzalez and [Andrei Paleyes](https://www.linkedin.com/in/andreipaleyes)\n",
    "at Amazon. Building on the experience of `GPyOpt`, the aim with Emukit\n",
    "was to use the modularisation ideas embedded in `GPyOpt`, but to extend\n",
    "them beyond the modularisation of the surrogate models to modularisation\n",
    "of the acquisition function.\n",
    "\n",
    "<img class=\"\" src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/emukit-software-page.png\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>The Emukit software is a set of software tools for emulation\n",
    "and surrogate modeling.\n",
    "<a href=\"https://emukit.github.io/emukit/\" class=\"uri\">https://emukit.github.io/emukit/</a></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyDOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install emukit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<svg viewBox=\"0 0 200 200\" style=\"width:10%\">\n",
    "\n",
    "<defs> <clipPath id=\"clip1\">\n",
    "\n",
    "<style>\n",
    "circle {\n",
    "  fill: black;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\"/> </clipPath> </defs>\n",
    "\n",
    "<title>\n",
    "\n",
    "Javier Gonzalez\n",
    "\n",
    "</title>\n",
    "\n",
    "<image preserveAspectRatio=\"xMinYMin slice\" width=\"100%\" xlink:href=\"../slides/diagrams/people/javier-gonzalez.png\" clip-path=\"url(#clip1)\"/>\n",
    "\n",
    "</svg>\n",
    "<svg viewBox=\"0 0 200 200\" style=\"width:10%\">\n",
    "\n",
    "<defs> <clipPath id=\"clip2\">\n",
    "\n",
    "<style>\n",
    "circle {\n",
    "  fill: black;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\"/> </clipPath> </defs>\n",
    "\n",
    "<title>\n",
    "\n",
    "Andrei Paleyes\n",
    "\n",
    "</title>\n",
    "\n",
    "<image preserveAspectRatio=\"xMinYMin slice\" width=\"100%\" xlink:href=\"../slides/diagrams/people/andrei-paleyes.jpg\" clip-path=\"url(#clip2)\"/>\n",
    "\n",
    "</svg>\n",
    "<svg viewBox=\"0 0 200 200\" style=\"width:10%\">\n",
    "\n",
    "<defs> <clipPath id=\"clip3\">\n",
    "\n",
    "<style>\n",
    "circle {\n",
    "  fill: black;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\"/> </clipPath> </defs>\n",
    "\n",
    "<title>\n",
    "\n",
    "Mark Pullin\n",
    "\n",
    "</title>\n",
    "\n",
    "<image preserveAspectRatio=\"xMinYMin slice\" width=\"100%\" xlink:href=\"../slides/diagrams/people/mark-pullin.jpg\" clip-path=\"url(#clip3)\"/>\n",
    "\n",
    "</svg>\n",
    "<svg viewBox=\"0 0 200 200\" style=\"width:10%\">\n",
    "\n",
    "<defs> <clipPath id=\"clip4\">\n",
    "\n",
    "<style>\n",
    "circle {\n",
    "  fill: black;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\"/> </clipPath> </defs>\n",
    "\n",
    "<title>\n",
    "\n",
    "Maren Mahsereci\n",
    "\n",
    "</title>\n",
    "\n",
    "<image preserveAspectRatio=\"xMinYMin slice\" width=\"100%\" xlink:href=\"../slides/diagrams/people/maren-mahsereci.png\" clip-path=\"url(#clip4)\"/>\n",
    "\n",
    "</svg>\n",
    "\n",
    "The software was initially built by the team in Amazon. As well as\n",
    "Javier Gonzalez (ML side) and Andrei Paleyes (Software Engineering)\n",
    "included Mark Pullin, Maren Mahsereci, Alex Gessner, Aaron Klein, Henry\n",
    "Moss, David-Elias Künstle as well as management input from Cliff\n",
    "McCollum and myself.\n",
    "\n",
    "<!--setupplotcode{import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context('paper')\n",
    "sns.set_palette('colorblind')}-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emukit Vision\n",
    "============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preface about emulation\n",
    "-----------------------\n",
    "\n",
    "We see emulation comprising of three main parts:\n",
    "\n",
    "**Models**. This is a probabilistic data-driven representation of the\n",
    "process/simulator that the user is working with. There is normally a\n",
    "modelling framework that is used to create a model. Examples: neural\n",
    "network, Gaussian process, random forest.\n",
    "\n",
    "**Methods**. Relatively low-level techniques that are aimed that either\n",
    "understanding, quantifying or using uncertainty that the model provides.\n",
    "Examples: Bayesian optimization, experimental design.\n",
    "\n",
    "**Tasks**. High level goals that owners of the process/simulator might\n",
    "be actually interested in. Examples: measure quality of a simulator,\n",
    "explain complex system behavior.\n",
    "\n",
    "Typical workflow that we envision for a user interested in emulation is:\n",
    "\n",
    "1.  Figure out which questions/tasks are important for them in regard to\n",
    "    their process/simulation.\n",
    "\n",
    "2.  Understand which emulation techniques are needed to accomplish the\n",
    "    chosen task.\n",
    "\n",
    "3.  Build an emulator of the process. That can be a very involved step,\n",
    "    that may include a lot of fine tuning and validation.\n",
    "\n",
    "Feed the emulator to the chosen technique and use it to answer the\n",
    "question/complete the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emukit and Emulation\n",
    "--------------------\n",
    "\n",
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/emukit-vision.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The emukit approach to the three parts of emulation.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods\n",
    "-------\n",
    "\n",
    "This is the main focus of Emukit. Emukit defines a general sctructure of\n",
    "a decision making method, called OuterLoop, and then offers\n",
    "implementations of few such methods: Bayesian optimization, experimental\n",
    "design. In addition to provide a framework for decision making Emukit\n",
    "provide other tools, like sensitivity analysis, that help to debug and\n",
    "interpret emulators. All methods in Emukit are model-agnostic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models\n",
    "------\n",
    "\n",
    "Generally speaking, Emukit does not provide modelling capabilities,\n",
    "instead expecting users to bring their own models. Because of the\n",
    "variety of modelling frameworks out there, Emukit does not mandate or\n",
    "make any assumptions about a particular modelling technique or a\n",
    "library. Instead it suggests to implement a subset of defined model\n",
    "interfaces required to use a particular method. Nevertheless, there are\n",
    "a few model-related functionalities in Emukit: - Example models, which\n",
    "give users something to play with to explore Emukit. - Model wrappers,\n",
    "which are designed to help adapting models in particular modelling\n",
    "frameworks to Emukit interfaces. - Multi-fidelity models, implemented\n",
    "based on GPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks\n",
    "-----\n",
    "\n",
    "Emukit does not contribute much to this part at the moment. However\n",
    "Emukit team are on lookout for typical use cases for Emukit, and if a\n",
    "reoccuring pattern emerges, it may become a part of the library.\n",
    "\n",
    "    while stopping condition is not met:\n",
    "        optimize acquisition function\n",
    "        evaluate user function\n",
    "        update model with new observation\n",
    "\n",
    "Emukit is build in a modular way so that each component in this loop can\n",
    "be swapped out. This means that scientists, applied mathematicians,\n",
    "machine learnings, statisticians can swap out the relavant part of their\n",
    "method and build on the undelrying structure. You just need to pick out\n",
    "the part that requires implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop\n",
    "----\n",
    "\n",
    "The `emukit.core.loop.OuterLoop` class is the abstract loop where the\n",
    "different components come together. There are more specific loops for\n",
    "Bayesian optimization and experimental design that construct some of the\n",
    "component parts for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model\n",
    "-----\n",
    "\n",
    "All `Emukit` loops need a probabilistic model of the underlying system.\n",
    "Emukit does not provide functionality to build models as there are\n",
    "already many good modelling frameworks available in python. Instead, we\n",
    "provide a way of interfacing third part modelling libraries with Emukit.\n",
    "We already provide a wrapper for using a model created with `GPy`. For\n",
    "instructions on how to include your own model please [see this\n",
    "notebook](https://emukit.readthedocs.io/en/latest/notebooks/Emukit-tutorial-custom-model.html).\n",
    "\n",
    "Different models and modelling frameworks will provide different\n",
    "functionality. For instance a Gaussian process will usually have\n",
    "derivatives of the predictions available but random forests will not.\n",
    "These different functionalities are represented by a set of interfaces\n",
    "which a model implements. The basic interface that all models must\n",
    "implement is `IModel`, which implements functionality to make\n",
    "predictions and update the model but a model may implement any number of\n",
    "other interfaces such as `IDifferentiable` which indicates a model has\n",
    "prediction derivatives available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidate Point Calculator\n",
    "--------------------------\n",
    "\n",
    "This class decides which point to evaluate next. The simplest\n",
    "implementation, `SequentialPointCalculator`, collects one point at a\n",
    "time by finding where the acquisition is a maximum by applying the\n",
    "acquisition optimizer to the acquisition function. More complex\n",
    "implementations will enable batches of points to be collected so that\n",
    "the user function can be evaluated in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquisition\n",
    "-----------\n",
    "\n",
    "The acquisition is a heuristic quantification of how valuable collecting\n",
    "a future point might be. It is used by the candidate point calculator to\n",
    "decide which point(s) to collect next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquisition Optimizer\n",
    "---------------------\n",
    "\n",
    "The `AcquisitionOptimizer` optimizes the acquisition function to find\n",
    "the point at which the acquisition is a maximum. This will use the\n",
    "acquisition function gradients if they are available. If gradients of\n",
    "the acquisition function are not available it will either estimate them\n",
    "numerically or use a gradient free optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Function\n",
    "-------------\n",
    "\n",
    "This is the function that we are trying to reason about. It can be\n",
    "either evaluated by the user or it can be passed into the loop and\n",
    "evaluated by Emukit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Updater\n",
    "-------------\n",
    "\n",
    "The `ModelUpdater` class updates the model with new training data after\n",
    "a new point is observed and optimizes any hyper-parameters of the model.\n",
    "It can decide whether hyper-parameters need updating based on some\n",
    "internal logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopping Condition\n",
    "------------------\n",
    "\n",
    "The `StoppingCondition` class chooses when we should stop collecting\n",
    "points. The most commonly used example is to stop when a set number of\n",
    "iterations have been reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emukit Tutorial\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/lawrennd/talks/gh-pages/teaching_plots.py','teaching_plots.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/lawrennd/talks/gh-pages/mlai.py','mlai.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/lawrennd/talks/gh-pages/gp_tutorial.py','gp_tutorial.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the python imports that Emukit will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import GPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set up Emukit to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emukit.experimental_design.experimental_design_loop import ExperimentalDesignLoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check the help function for the experimental design loop. This is\n",
    "the outer loop that provides all the decision making parts of Emukit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentalDesignLoop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s load in the model wrapper for our probabilistic model. In this\n",
    "case, instead of using GPy, we’ll make use of a simple model wrapper\n",
    "Emukit provides for a basic form of Gaussian process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emukit.model_wrappers import SimpleGaussianProcessModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s have a quick look at how the included GP model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimpleGaussianProcessModel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s create the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = -30.0\n",
    "x_max = 30.0\n",
    "\n",
    "x = np.random.uniform(x_min, x_max, (10, 1))\n",
    "y = np.sin(x) + np.random.randn(10, 1) * 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn about how to include your own model in Emukit, check [this\n",
    "notebook](https://github.com/EmuKit/emukit/blob/master/notebooks/Emukit-tutorial-custom-model.ipynb)\n",
    "which shows how to include a `sklearn` GP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emukit_model = SimpleGaussianProcessModel(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emukit.core import ParameterSpace, ContinuousParameter\n",
    "from emukit.core.loop import UserFunctionWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ContinuousParameter('c', x_min, x_max)\n",
    "space = ParameterSpace([p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = ExperimentalDesignLoop(space, emukit_model)\n",
    "loop.run_loop(np.sin, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_min = -40.0\n",
    "plot_max = 40.0\n",
    "\n",
    "real_x = np.arange(plot_min, plot_max, 0.2)\n",
    "real_y = np.sin(real_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import teaching_plots as plot\n",
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "\n",
    "ax.plot(real_x, real_y, c='r', linewidth=2)\n",
    "ax.scatter(loop.loop_state.X[:, 0].tolist(), \n",
    "           loop.loop_state.Y[:, 0].tolist(), s=50)\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$', rotation=None)\n",
    "ax.set_ylim([-2.5, 2.5])\n",
    "\n",
    "ax.legend(['true function', 'acquired data points'], loc='lower right')\n",
    "\n",
    "mlai.write_figure('emukit-sine-function.svg', directory='./uq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/emukit-sine-function.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Experimental design in Emukit using the\n",
    "`ExperimentalDesignLoop`: learning function $\\sin(x)$ with Emukit.</i>\n",
    "\n",
    "Computer the predictions from the Emukit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = []\n",
    "predicted_std = []\n",
    "for x in real_x:\n",
    "    y, var = emukit_model.predict(np.array([[x]]))\n",
    "    std = np.sqrt(var)\n",
    "    predicted_y.append(y)\n",
    "    predicted_std.append(std)\n",
    "\n",
    "predicted_y = np.array(predicted_y).flatten()\n",
    "predicted_std = np.array(predicted_std).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "\n",
    "ax.plot(real_x, predicted_y, linewidth=3)\n",
    "ax.plot(real_x, real_y, c='r', linewidth=2)\n",
    "\n",
    "ax.set_ylim([-2.5, 2.5])\n",
    "\n",
    "ax.fill_between(real_x, predicted_y - 2 * predicted_std, \n",
    "                predicted_y + 2 * predicted_std, alpha=.5)\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.legend(['true function', 'estimated function'], loc='lower right')\n",
    "\n",
    "mlai.write_figure('emukit-sine-function-fit.svg', directory='./uq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/emukit-sine-function-fit.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The fit to the sine function after runnning the Emukit\n",
    "`ExperimentalDesignLoop`.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Repeat the above experiment but using the Gaussian process model from\n",
    "`sklearn`. You can see step by step instructions on how to do this in\n",
    "[this\n",
    "notebook](https://github.com/EmuKit/emukit/blob/master/notebooks/Emukit-tutorial-custom-model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer to Exercise 1 here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emukit Overview Summary\n",
    "-----------------------\n",
    "\n",
    "The aim is to provide a suite where different approaches to emulation\n",
    "are assimilated under one roof. The current version of Emukit includes\n",
    "*multi-fidelity emulation* for build surrogate models when data is\n",
    "obtained from multiple information sources that have different fidelity\n",
    "and/or cost; *Bayesian optimisation* for optimising physical experiments\n",
    "and tune parameters of machine learning algorithms or other\n",
    "computational simulations; *experimental design and active learning*:\n",
    "design the most informative experiments and perform active learning with\n",
    "machine learning models; *sensitivity analysis*: analyse the influence\n",
    "of inputs on the outputs of a given system; and *Bayesian quadrature*:\n",
    "efficiently compute the integrals of functions that are expensive to\n",
    "evaluate. But it’s easy to extend.\n",
    "\n",
    "This introduction is based on [An Introduction to Experimental Design\n",
    "with\n",
    "Emukit](https://github.com/EmuKit/emukit/blob/master/notebooks/Emukit-tutorial-experimental-design-introduction.ipynb)\n",
    "written by Andrei Paleyes and Maren Mahsereci."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alex Forrester\n",
    "--------------\n",
    "\n",
    "<svg viewBox=\"0 0 200 200\" style=\"width:15%\">\n",
    "\n",
    "<defs> <clipPath id=\"clip5\">\n",
    "\n",
    "<style>\n",
    "circle {\n",
    "  fill: black;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\"/> </clipPath> </defs>\n",
    "\n",
    "<title>\n",
    "\n",
    "Alex Forrester\n",
    "\n",
    "</title>\n",
    "\n",
    "<image preserveAspectRatio=\"xMinYMin slice\" width=\"100%\" xlink:href=\"../slides/diagrams/people/alex-forrester.jpg\" clip-path=\"url(#clip5)\"/>\n",
    "\n",
    "</svg>\n",
    "\n",
    "We’re going to make use of the Forrester function in our example below,\n",
    "a function developed as a demonstrator by [Alex\n",
    "Forrester](https://www.southampton.ac.uk/engineering/research/groups/performance-sports/staff-profiles/alexander-forrester.page).\n",
    "Alex is a design engineer who makes extensive use of surrogate modelling\n",
    "in Engineering design.\n",
    "\n",
    "You can see Alex talking about the use of Gaussian process surrogates\n",
    "[in this online video\n",
    "lecture](http://videolectures.net/mla09_forrester_sbcmoo/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('2ngc2aw9xYs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>A kinematic simulation of the human body doing breaststroke\n",
    "that Alex uses as part of his work in optimization of human motion\n",
    "during sports.</i>\n",
    "\n",
    "The Forrester function (Forrester et al., 2008) is commonly used as a\n",
    "demonstrator function in surrogate modelling. It has the form $$\n",
    "f(x) = (6x-2)^2\\sin(12 x-4).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 100)\n",
    "f = (6*x-2)**2 * np.sin(12*x-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import teaching_plots as plot\n",
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "ax.plot(x, f, 'r-', linewidth=2)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$f(x)$')\n",
    "ax.set_xlim(-0.01, 1)\n",
    "ax.set_ylim([-20, 20])\n",
    "\n",
    "mlai.write_figure('forrester-function.svg', directory='./uq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/forrester-function.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The Forrester function is commonly used as an exemplar\n",
    "function for surrogate modelling and emulation. It has the form\n",
    "$f(x) = (6x-2)^2\\sin(12 x-4)$</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental Design in Emukit\n",
    "=============================\n",
    "\n",
    "We’re going to introduce the experimental design acquisiton functions by\n",
    "looking at the Forrester function (Forrester et al., 2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from emukit.test_functions import forrester_function\n",
    "from emukit.core.loop.user_function import UserFunctionWrapper\n",
    "from emukit.core import ContinuousParameter, ParameterSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_function, space = forrester_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(space.parameters[0].min, space.parameters[0].max, 301)[:, None]\n",
    "y_plot = target_function(x_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "ax.plot(x_plot, y_plot, 'k', label='target Function', linewidth=2)\n",
    "\n",
    "ax.legend(loc=2)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$f(x)$')\n",
    "ax.grid(True)\n",
    "ax.set_xlim(0, 1)\n",
    "\n",
    "mlai.write_figure(filename='forrester-function.svg', directory='./uq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/forrester-function.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The Forrester function (Forrester et al., 2008).</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Design\n",
    "--------------\n",
    "\n",
    "Usually, before we start the actual ExpDesign loop we need to gather a\n",
    "few observations such that we can fit the model. This is called the\n",
    "initial design and common strategies are either a predefined grid or\n",
    "sampling points uniformly at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_init = np.array([[0.2],[0.6], [0.9]])\n",
    "Y_init = target_function(X_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "ax.plot(X_init, Y_init, 'ro', markersize=10, label='observations')\n",
    "ax.plot(x_plot, y_plot, 'k', label='target Function', linewidth=2)\n",
    "\n",
    "ax.legend(loc=2)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$f(x)$')\n",
    "ax.grid(True)\n",
    "ax.set_xlim(-0.01, 1)\n",
    "ax.set_ylim([-20, 20])\n",
    "\n",
    "mlai.write_figure(filename='forrester-function-initial-design.svg', directory='./uq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/forrester-function-initial-design.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The initial design for the Forrester function example.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model\n",
    "---------\n",
    "\n",
    "Now we can start with the ExpDesign loop by first fitting a model on the\n",
    "collected data. A popular model for ExpDesign is a Gaussian process (GP)\n",
    "which defines a probability distribution across classes of functions,\n",
    "typically smooth, such that each linear finite-dimensional restriction\n",
    "is multivariate Gaussian (Rasmussen and Williams, 2006). Gaussian\n",
    "processes are fully parametrized by a mean $\\mu(\\mathbf{ x})$ and a\n",
    "covariance function $k(\\mathbf{ x},\\mathbf{ x}^\\prime)$. Without loss of\n",
    "generality $\\mu(\\mathbf{ x})$ is assumed to be zero. The covariance\n",
    "function $k(\\mathbf{ x},\\mathbf{ x}^\\prime)$ characterizes the\n",
    "smoothness and other properties of $f$. It is known that the kernel of\n",
    "the process has to be continuous, symmetric and positive definite. A\n",
    "widely used kernel is the exponentiated quadratic or RBF kernel: $$ \n",
    "k(\\mathbf{ x},\\mathbf{ x}^\\prime) = \\alpha \\exp{ \\left(-\\frac{\\|\\mathbf{ x}-\\mathbf{ x}^\\prime\\|^2}{2 \\ell}\\right)} \n",
    "$$ where $\\alpha$ and $\\ell$ are hyperparameters.\n",
    "\n",
    "To denote that $f$ is a sample from a GP with mean $\\mu$ and covariance\n",
    "$k$ we write $$\n",
    "f\\sim \\mathcal{GP}(\\mu,k).\n",
    "$$\n",
    "\n",
    "For regression tasks, the most important feature of GPs is that process\n",
    "priors are conjugate to the likelihood from finitely many observations\n",
    "$\\mathbf{Y}= (y_1,\\dots,y_n)^\\top$ and\n",
    "$\\mathbf{X}=\\{\\mathbf{ x}_1,\\dots,\\mathbf{ x}_n\\}$,\n",
    "$\\mathbf{ x}_i\\in \\mathcal{X}$ of the form\n",
    "$y_i = f(\\mathbf{ x}_i) + \\epsilon_i$ where\n",
    "$\\epsilon_i \\sim \\mathcal{N}\\left(0,\\sigma^2\\right)$ and we typically\n",
    "estimate $\\sigma^2$ by maximum likelihood alongside $\\alpha$ and $\\ell$.\n",
    "\n",
    "We obtain the Gaussian posterior $$\n",
    "f(\\mathbf{ x}^*)|\\mathbf{X}, \\mathbf{Y}, \\theta \\sim \\mathcal{N}\\left(\\mu(\\mathbf{ x}^*),\\sigma^2(\\mathbf{ x}^*)\\right),\n",
    "$$ where $\\mu(\\mathbf{ x}^*)$ and $\\sigma^2(\\mathbf{ x}^*)$ have a\n",
    "closed form solution as we’ve seen in the earlier lectures (see also\n",
    "Rasmussen and Williams (2006)).\n",
    "\n",
    "Note that Gaussian processes are also characterized by hyperparameters,\n",
    "for example in the exponentiated quadratic case we have\n",
    "$\\boldsymbol{ \\theta}= \\left\\{ \\alpha, \\ell, \\sigma^2 \\right\\}$ for the\n",
    "scale of the covariance, the lengthscale and the noise variance. Here,\n",
    "for simplicitly we will keep these hyperparameters fixed. However, we\n",
    "will usually either optimize or sample these hyperparameters using the\n",
    "marginal loglikelihood of the GP.\n",
    "\n",
    "In this module we’ve focussed on Gaussian processes, but we could also\n",
    "use any other model that returns a mean $\\mu(\\mathbf{ x})$ and variance\n",
    "$\\sigma^2(\\mathbf{ x})$ on an arbitrary input points $\\mathbf{ x}$ such\n",
    "as Bayesian neural networks or random forests. In Emukit these different\n",
    "models can also be used by defining a new `ModelWrapper`.\n",
    "\n",
    "Here we’re going to wrap a GPy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "from emukit.model_wrappers.gpy_model_wrappers import GPyModelWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up the covariance function for the GPy model, initialising it\n",
    "with a lengthscale, $\\ell=0.08$, and a variance, $\\alpha=20$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kern = GPy.kern.RBF(1, lengthscale=0.08, variance=20)\n",
    "gpy_model = GPy.models.GPRegression(X_init, Y_init, kern, noise_var=1e-10)\n",
    "emukit_model = GPyModelWrapper(gpy_model)\n",
    "\n",
    "mu_plot, var_plot = emukit_model.predict(x_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import colors as mcolors\n",
    "from matplotlib import cm\n",
    "\n",
    "colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_plot_emulator_errorbars():\n",
    "    \"\"\"Helper function for plotting the emulator fit.\"\"\"\n",
    "    ax.plot(emukit_model.X, emukit_model.Y, 'ro', markersize=10, label='observations')\n",
    "    ax.plot(x_plot, mu_plot, 'C0', label='model', linewidth=3)\n",
    "    ax.plot(x_plot, y_plot, 'k', label='target function', linewidth=2)\n",
    "    ax.fill_between(x_plot[:, 0],\n",
    "                 mu_plot[:, 0] + np.sqrt(var_plot)[:, 0],\n",
    "                 mu_plot[:, 0] - np.sqrt(var_plot)[:, 0], color='C0', alpha=0.6)\n",
    "    ax.fill_between(x_plot[:, 0],\n",
    "                 mu_plot[:, 0] + 2 * np.sqrt(var_plot)[:, 0],\n",
    "                 mu_plot[:, 0] - 2 * np.sqrt(var_plot)[:, 0], color='C0', alpha=0.4)\n",
    "    ax.fill_between(x_plot[:, 0],\n",
    "                 mu_plot[:, 0] + 3 * np.sqrt(var_plot)[:, 0],\n",
    "                 mu_plot[:, 0] - 3 * np.sqrt(var_plot)[:, 0], color='C0', alpha=0.2)\n",
    "    ax.legend(loc=2)\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$f(x)$')\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim(-0.01, 1)\n",
    "    ax.set_ylim([-20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "helper_plot_emulator_errorbars()\n",
    "mlai.write_figure(filename='forrester-function-multi-errorbars-00.svg', directory='./uq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/forrester-function-multi-errorbars-00.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The emulator fitted to the Forrester function with only three\n",
    "observations from the inital design. The error bars show 1, 2 and 3\n",
    "standard deviations.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Acquisition Function\n",
    "------------------------\n",
    "\n",
    "In the second step of our ExpDesign loop we use our model to compute the\n",
    "acquisition function. We’ll review two different forms of acquisition\n",
    "funciton for doing this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty Sampling\n",
    "\n",
    "In uncertainty sampling (US) we hoose the next value $\\mathbf{ x}_{n+1}$\n",
    "at the location where the model on $f(\\mathbf{ x})$ has the highest\n",
    "marginal predictive variance $$\n",
    "a_{US}(\\mathbf{ x}) = \\sigma^2(\\mathbf{ x}).\n",
    "$$ This makes sure, that we learn the function $f(\\cdot)$ everywhere on\n",
    "$\\mathbb{X}$ to a similar level of absolute error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrated Variance Reduction\n",
    "\n",
    "In the integrated variance reduction (IVR) you choose the next value\n",
    "$\\mathbf{ x}_{n+1}$ such that the total variance of the model is reduced\n",
    "maximally (Sacks et al., 1989), $$\n",
    "\\begin{align*}\n",
    "a_{IVR} & = \\int_{\\mathbb{X}}[\\sigma^2(\\mathbf{ x}') - \\sigma^2(\\mathbf{ x}'; \\mathbf{ x})]\\text{d}\\mathbf{ x}' \\\\\n",
    "& \\approx \n",
    "\\frac{1}{\\# \\text{samples}}\\sum_i^{\\# \\text{samples}}[\\sigma^2(\\mathbf{ x}_i) - \\sigma^2(\\mathbf{ x}_i; \\mathbf{ x})].\n",
    "\\end{align*}\n",
    "$$ Here $\\sigma^2(\\mathbf{ x}'; \\mathbf{ x})$ is the predictive variance\n",
    "at $\\mathbf{ x}'$ had $\\mathbf{ x}$ been observed. Thus IVR computes the\n",
    "overall reduction in variance (for all points in $\\mathbb{X}$) had $f$\n",
    "been observed at $\\mathbf{ x}$.\n",
    "\n",
    "The finite sum approximation on the right hand side of the equation is\n",
    "usually used because the integral over $\\mathbf{ x}'$ is not analytic.\n",
    "In that case $\\mathbf{ x}_i$ are sampled randomly. For a GP model the\n",
    "right hand side simplifies to\n",
    "\n",
    "$$\n",
    "a_{LCB} \\approx \\frac{1}{\\# \\text{samples}}\\sum_i^{\\# \\text{samples}}\\frac{k^2(\\mathbf{ x}_i, \\mathbf{ x})}{\\sigma^2(\\mathbf{ x})}.\n",
    "$$\n",
    "\n",
    "IVR is arguably the more principled approach, but often US is preferred\n",
    "over IVR simply because it lends itself to gradient based optimization\n",
    "more easily, is cheaper to compute, and is exact.\n",
    "\n",
    "For both of them (stochastic) gradient base optimizers are used to\n",
    "retrieve\n",
    "$\\mathbf{ x}_{n+1} \\in \\operatorname*{arg\\:max}_{\\mathbf{ x}\\in \\mathbb{X}} a(\\mathbf{ x})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emukit.experimental_design.acquisitions import IntegratedVarianceReduction, ModelVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acquisition = ModelVariance(emukit_model)\n",
    "ivr_acquisition = IntegratedVarianceReduction(emukit_model, space)\n",
    "\n",
    "us_plot = us_acquisition.evaluate(x_plot)\n",
    "ivr_plot = ivr_acquisition.evaluate(x_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "ax.plot(x_plot, us_plot / np.max(us_plot), 'green', label='US', linewidth=3)\n",
    "ax.plot(x_plot, ivr_plot / np.max(ivr_plot) , 'purple', label='IVR', linewidth=3)\n",
    "\n",
    "ax.legend(loc=1)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$f(x)$')\n",
    "ax.grid(True)\n",
    "ax.set_xlim(-0.01, 1)\n",
    "\n",
    "mlai.write_figure('experimental-design-acquisition-forrester-00.svg', directory='./uq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/experimental-design-acquisition-forrester-00.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The *uncertainty sampling* and *integrated variance\n",
    "reduction* acquisition functions for the Forrester example.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the objective function\n",
    "---------------------------------\n",
    "\n",
    "To find the next point to evaluate we optimize the acquisition function\n",
    "using a standard gradient descent optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_plot_next_point_acquisition():\n",
    "    \"\"\"Helper code for plot the location of the next point acquisition.\"\"\"\n",
    "    ax.plot(x_plot, us_plot / np.max(us_plot), 'green', label='US', linewidth=3)\n",
    "    ax.axvline(x_new, color='red', label='x_next', linestyle='--', linewidth=3)\n",
    "    ax.legend(loc=1)\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$f(x)$')\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim(-0.01, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emukit.core.optimization import GradientAcquisitionOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = GradientAcquisitionOptimizer(space)\n",
    "x_new, _ = optimizer.optimize(us_acquisition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "helper_plot_next_point_acquisition()\n",
    "mlai.write_figure('experimental-design-acquisition-forrester-01.svg', directory='./uq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/experimental-design-acquisition-forrester-01.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The maxima of the acquisition function is found and this\n",
    "point is selected for inclusion.</i>\n",
    "\n",
    "Afterwards we evaluate the true objective function and append it to our\n",
    "initial observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = target_function(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(X_init, x_new, axis=0)\n",
    "Y = np.append(Y_init, y_new, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After updating the model, you can see that the uncertainty about the\n",
    "true objective function in this region decreases and our model becomes\n",
    "more certain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emukit_model.set_data(X, Y)\n",
    "mu_plot, var_plot = emukit_model.predict(x_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "helper_plot_emulator_errorbars()\n",
    "\n",
    "mlai.write_figure(filename='forrester-function-multi-errorbars-01.svg', directory='./uq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/forrester-function-multi-errorbars-01.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The target Forrester function plotted alongside the emulation\n",
    "model and error bars from the emulation at 1, 2 and 3 standard\n",
    "deviations.</i>\n",
    "\n",
    "We can repeat this process to obtain more points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acquisition = ModelVariance(emukit_model)\n",
    "us_plot = us_acquisition.evaluate(x_plot)\n",
    "x_new, _ = optimizer.optimize(us_acquisition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "helper_plot_next_point_acquisition()\n",
    "\n",
    "mlai.write_figure('experimental-design-acquisition-forrester-02.svg', directory='./uq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/experimental-design-acquisition-forrester-02.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The maxima of the acquisition function is found and this\n",
    "point is selected for inclusion.</i>\n",
    "\n",
    "Once again we can asimmilate the new target function observation into\n",
    "the model and re-evaluate our emulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = target_function(x_new)\n",
    "X = np.append(X, x_new, axis=0)\n",
    "Y = np.append(Y, y_new, axis=0)\n",
    "emukit_model.set_data(X, Y)\n",
    "mu_plot, var_plot = emukit_model.predict(x_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting in an updated estimate of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "helper_plot_emulator_errorbars()\n",
    "\n",
    "mlai.write_figure(filename='forrester-function-multi-errorbars-02.svg', directory='./uq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/forrester-function-multi-errorbars-02.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The target Forrester function plotted alongside the emulation\n",
    "model and error bars from the emulation at 1, 2 and 3 standard\n",
    "deviations.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emukit’s Experimental Design Interface\n",
    "--------------------------------------\n",
    "\n",
    "Of course in practice we don’t want to implement all of these steps our\n",
    "self. Emukit provides a convenient and flexible interface to apply\n",
    "experimental design. Below we can see how to run experimental design on\n",
    "the exact same function for 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emukit.experimental_design.experimental_design_loop import ExperimentalDesignLoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed = ExperimentalDesignLoop(space=space, model=emukit_model)\n",
    "\n",
    "ed.run_loop(target_function, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_plot, var_plot = ed.model.predict(x_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "helper_plot_emulator_errorbars()\n",
    "\n",
    "mlai.write_figure(filename='forrester-function-full-fit.svg', directory='./uq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/uq/forrester-function-full-fit.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The fit of the model to the Forrester function.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions\n",
    "-----------\n",
    "\n",
    "We’ve introduced the Emukit software and outlined its design philosophy.\n",
    "We’ve then performed some simple examples using Emukit to perform\n",
    "*experimental design* as a task. In particular we saw how we could\n",
    "define the task as an acquisition funciton, a loop, an emulator model\n",
    "and a target function.\n",
    "\n",
    "You can compare the design of this software with its predecessor,\n",
    "`GPyOpt`, which is less modular in its design, and more focussed on\n",
    "Bayesian optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks!\n",
    "-------\n",
    "\n",
    "For more information on these subjects and more you might want to check\n",
    "the following resources.\n",
    "\n",
    "-   twitter: [@lawrennd](https://twitter.com/lawrennd)\n",
    "-   podcast: [The Talking Machines](http://thetalkingmachines.com)\n",
    "-   newspaper: [Guardian Profile\n",
    "    Page](http://www.theguardian.com/profile/neil-lawrence)\n",
    "-   blog:\n",
    "    [http://inverseprobability.com](http://inverseprobability.com/blog.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forrester, A.I.J., Sóbester, A., Keane, A.J., 2008. Engineering design\n",
    "via surrogate modelling: A practical guide. wiley.\n",
    "<https://doi.org/10.1002/9780470770801>\n",
    "\n",
    "Rasmussen, C.E., Williams, C.K.I., 2006. Gaussian processes for machine\n",
    "learning. mit, Cambridge, MA.\n",
    "\n",
    "Sacks, J., Welch, W.J., Mitchell, T.J., Wynn, H.P., 1989. Design and\n",
    "analysis of computer experiments. Statistical Science 4, 409–423.\n",
    "<https://doi.org/10.1214/ss/1177012413>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
